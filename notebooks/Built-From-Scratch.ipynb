{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e743b0",
   "metadata": {},
   "source": [
    "## CONTRASTIVE BLIND SUPER RESOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b681b3",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceef6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import cv2\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e236bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.image import extract_patches_2d as patch_ex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fbdde",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f228e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing LR images according to equation 1.\n",
    "#Prepares LR images and saves it to a folder\n",
    "\n",
    "def Prep_LR(HR_path,LR_path,HR_patch_path, LR_patch_path,SR_scale):\n",
    "    \n",
    "    #path is source of Training images\n",
    "    HR_filenames = os.listdir(HR_path)\n",
    "    \n",
    "    \n",
    "    #Loop that takes an image, synthesizes its LR and saves it\n",
    "    \n",
    "    for file in HR_filenames :\n",
    "        \n",
    "        HR = img.imread(HR_path + file)\n",
    "        \n",
    "        #GAussian Blur\n",
    "        gaussian_blurred = cv2.GaussianBlur(HR,(0,0),4.0)\n",
    "        \n",
    "        #Bicubic Downsampling\n",
    "        dim  = (int((HR.shape[0]/int(SR_scale))),int((HR.shape[1]/int(SR_scale))))\n",
    "        bicubic_downsampled = cv2.resize(gaussian_blurred,dim, interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        \n",
    "        #Adding Noise\n",
    "        LR = skimage.util.random_noise(bicubic_downsampled)\n",
    "        \n",
    "        #SAving the LR Image\n",
    "        plt.imsave(LR_path + file ,LR, format= 'png')\n",
    "        \n",
    "        \n",
    "        #Patch extraction : 2 random patches from each image is cropped out and saved\n",
    "        \n",
    "        LR_patches = patch_ex(LR, (64,64), max_patches=2, random_state=23)\n",
    "        plt.imsave(LR_patch_path + 'p1' + file, LR_patches[0], format = 'png')\n",
    "        plt.imsave(LR_patch_path + 'p2' + file, LR_patches[1], format = 'png')\n",
    "\n",
    "        HR_patches = patch_ex(HR, (64,64), max_patches=2, random_state=23)\n",
    "        plt.imsave(HR_patch_path + 'p1' + file, HR_patches[0], format = 'png')\n",
    "        plt.imsave(HR_patch_path + 'p2' + file, HR_patches[1], format = 'png')\n",
    "        \n",
    "        \n",
    "        \n",
    "                                            \n",
    "                            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe84df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = '/home/bastin/PROJECT-main/Data/Train/HR/'\n",
    "L = '/home/bastin/PROJECT-main/Data/Train/LR/'\n",
    "H_patch = '/home/bastin/PROJECT-main/Data/Train/Patch_HR/'\n",
    "L_patch = '/home/bastin/PROJECT-main/Data/Train/Patch_LR/'\n",
    "scale = 4\n",
    "\n",
    "Prep_LR(H,L,H_patch,L_patch,scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d9f295",
   "metadata": {},
   "source": [
    " ### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50553616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Contrastive loss (L_degrad)\n",
    "\n",
    "\n",
    "def ContraLoss(zi, zj, tau=1):\n",
    "    \n",
    "    \n",
    "    z = tf.cast(tf.concat((zi, zj), 0), dtype=tf.float32)\n",
    "    loss = 0\n",
    "    for k in range(zi.shape[0]):\n",
    "        # Numerator (compare i,j & j,i)\n",
    "        i = k\n",
    "        j = k + zi.shape[0]\n",
    "        # Instantiate the cosine similarity loss function\n",
    "        cosine_sim = tf.keras.losses.CosineSimilarity(axis=-1, reduction=tf.keras.losses.Reduction.NONE)\n",
    "        sim = tf.squeeze(- cosine_sim(tf.reshape(z[i], (1, -1)), tf.reshape(z[j], (1, -1))))\n",
    "        numerator = tf.math.exp(sim / tau)\n",
    "\n",
    "        # Denominator (compare i & j to all samples apart from themselves)\n",
    "        sim_ik = - cosine_sim(tf.reshape(z[i], (1, -1)), z[tf.range(z.shape[0]) != i])\n",
    "        sim_jk = - cosine_sim(tf.reshape(z[j], (1, -1)), z[tf.range(z.shape[0]) != j])\n",
    "        denominator_ik = tf.reduce_sum(tf.math.exp(sim_ik / tau))\n",
    "        denominator_jk = tf.reduce_sum(tf.math.exp(sim_jk / tau))\n",
    "\n",
    "        # Calculate individual and combined losses\n",
    "        loss_ij = - tf.math.log(numerator / denominator_ik)\n",
    "        loss_ji = - tf.math.log(numerator / denominator_jk)\n",
    "        loss += loss_ij + loss_ji\n",
    "    \n",
    "    # Divide by the total number of samples\n",
    "    loss /= z.shape[0]\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ce4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc907b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c399bb8",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eefbd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = keras.models.Sequential()\n",
    "\n",
    "\n",
    "Encoder.add(layers.Conv2D(input_shape = (512,512,3), filters = 64, kernel_size = 3,))\n",
    "Encoder.add(layers.BatchNormalization())\n",
    "Encoder.add(layers.LeakyReLU(0.1))\n",
    "            \n",
    "Encoder.add(layers.Conv2D(filters = 128, kernel_size = 3))\n",
    "Encoder.add(layers.BatchNormalization())\n",
    "Encoder.add(layers.LeakyReLU(0.1))\n",
    "            \n",
    "Encoder.add(layers.Conv2D(filters = 256, kernel_size = 3))\n",
    "Encoder.add(layers.BatchNormalization())\n",
    "Encoder.add(layers.LeakyReLU(0.1))\n",
    "\n",
    "Encoder.add(layers.AveragePooling2D(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94dc226",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_head = keras.models.Sequential()\n",
    "\n",
    "projection_head.add(layers.Flatten())\n",
    "projection_head.add(layers.Dense(256))\n",
    "projection_head.add(layers.LeakyReLU(0.1))\n",
    "projection_head.add(layers.Dense(256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bc5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Degradation_Encoder = keras.models.Sequential(Encoder,projection_head)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2778e626",
   "metadata": {},
   "source": [
    "Degradation_Encoder.compile(loss = ContraLoss, optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b693c2",
   "metadata": {},
   "source": [
    "### Super Resolution Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c10e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recieves a concatenated tensor x, where x[0] = feature map, and x[1] = degardation representation\n",
    "# shape of feature map = batchsize x channels x height x width\n",
    "# shape of degradation representation = batchsize x channels\n",
    "\n",
    "input1 = layers.Input(shape = (512,512,1), batch_size = 32)\n",
    "input2 = layers.Input(shape =(None,1) , batch_size = 32)\n",
    "\n",
    "#resizing the degradation representation\n",
    "resized_deg_rep = layers.Dense(64)(input2)\n",
    "resized_deg_rep = layers.LeakyReLU(0.1)(resized_deg_rep)\n",
    "resized_deg_rep = layers.Dense(64)(resized_deg_rep)\n",
    "\n",
    "#Convolutions on input image\n",
    "feat = layers.Conv2D(filters= 64, kernel_size = 3)(input1)\n",
    "feat = layers.LeakyReLU(0.1)(feat)\n",
    "feat = layers.Conv2D(filters= 64, kernel_size = 3)(feat)\n",
    "feat = layers.LeakyReLU(0.1)(feat)\n",
    "out = feat + resized_deg_rep\n",
    "\n",
    "\n",
    "out = layers.Conv2D(filters= 64, kernel_size = 3)(out)\n",
    "out = layers.LeakyReLU(0.1)(out)\n",
    "out = layers.Conv2D(filters= 64, kernel_size = 3)(out)\n",
    "out = layers.LeakyReLU(0.1)(out)\n",
    "out = out + resized_deg_rep\n",
    "\n",
    "out = layers.Conv2D(filters= 64, kernel_size = 3)(out)\n",
    "out = layers.LeakyReLU(0.1)(out)\n",
    "out = layers.Conv2D(filters= 64, kernel_size = 3)(out)\n",
    "out = layers.LeakyReLU(0.1)(out)\n",
    "out = out + resized_deg_rep\n",
    "\n",
    "#Upsampling\n",
    "out = layers.Flatten(out)\n",
    "out = layers.Dense(512*512)(out)\n",
    "\n",
    "Generator = keras.Model(inputs = [input1,input2], outputs = out)\n",
    "Generator.compile(loss = )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f315765",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "priming_epochs = 50\n",
    "epochs = 300\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "train_generator = train_datagen.flow_from_directory('HR_path', target_size=(512,512),batch_size=32)\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory('test_path', target_size=(512,512),batch_size=32)\n",
    "\n",
    "\n",
    "for epoch in epochs:\n",
    "    \n",
    "    if epoch <= priming_epochs:\n",
    "        Degradation_Encoder.fit(train_generator,epochs=1,validation_data=test_generator)\n",
    "\n",
    "\n",
    "    else :\n",
    "        Degradation_Encoder.fit(train_generator,epochs=1,validation_data=test_generator)\n",
    "        Generator.fit(train_generator,epochs = 1, validation_data = test_generator)\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fe53ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
